ğŸµ Emotion-Controlled Music Generation with AI
A Deep Learning System That Detects Emotion & Generates Music Using MusicGen + CV + Voice
ğŸš€ Project Overview

This project is an AI-powered music generation system that automatically creates personalized music based on user emotion.
The system captures emotion using either:

Face emotion detection (camera input)

Voice emotion detection (audio input)

Once the emotion is detected, the app uses Metaâ€™s MusicGen model running on GPU (Colab/Cloud) to generate a custom music track.
Tracks are saved, played, regenerated, liked, and downloaded through a responsive React + Vite UI with MongoDB backend.

âœ¨ Features
ğŸ­ Emotion Detection

Face-based emotion classification using a CNN (TensorFlow/Keras).

Supports emotions: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral.

ğŸ¶ AI Music Generation

Uses MusicGen-Small model from Facebook AI.

Generates 20-second high-quality music based on emotion â†’ text prompt mapping.

Supports variation/regeneration of tracks.

ğŸ“ Music Library

View all generated tracks

Play music with waveform using Wavesurfer.js

Like, save, delete, and download tracks

Tracks stored in MongoDB Atlas

ğŸ”¥ Backend: Flask + Colab GPU

Flask REST API

MusicGen running on external Colab GPU over ngrok

Full CORS-enabled architecture

Saves audio files under /static/generated/

ğŸ¨ Frontend: React + Vite

Modern UI

Beautiful music cards

Tabs: Generated Music and My Uploads

Toast notifications

Audio waveform + Play/Pause control

ğŸ§  Tech Stack
Frontend

React + TypeScript

Vite

ShadCN/UI

Wavesurfer.js

Backend

Python Flask

TensorFlow/Keras (Emotion detection)

MusicGen (HuggingFace Transformers)

Pyngrok (Colab Tunnel)

MongoDB Atlas

Requests, NumPy, PIL, etc.

ğŸ“¦ Project Architecture
frontend/
 â”œâ”€â”€ src/
 â”‚   â”œâ”€â”€ components/
 â”‚   â”‚   â”œâ”€â”€ MusicCard.tsx
 â”‚   â”‚   â”œâ”€â”€ Waveform.tsx
 â”‚   â”‚   â”œâ”€â”€ Navbar.tsx
 â”‚   â”œâ”€â”€ pages/
 â”‚   â”‚   â”œâ”€â”€ FaceDetection.tsx
 â”‚   â”‚   â”œâ”€â”€ VoiceDetection.tsx
 â”‚   â”‚   â”œâ”€â”€ Library.tsx
 â”‚   â”œâ”€â”€ App.tsx
 â”‚   â””â”€â”€ main.tsx

backend/
 â”œâ”€â”€ app.py
 â”œâ”€â”€ emotion_model.h5
 â”œâ”€â”€ static/
 â”‚   â””â”€â”€ generated/
 â”œâ”€â”€ requirements.txt

ğŸ”§ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/Kishor237323/Emotional-Controlled-Music-Generation-with-AI.git
cd Emotional-Controlled-Music-Generation-with-AI

2ï¸âƒ£ Install Backend Dependencies
cd backend
pip install -r requirements.txt

3ï¸âƒ£ Start Flask Server
python app.py

4ï¸âƒ£ Enable GPU MusicGen (Colab)

Run the provided Colab notebook â†’ copy ngrok URL â†’ paste into Flask COLAB_URL.

5ï¸âƒ£ Start Frontend
cd frontend
npm install
npm run dev

ğŸ§ How Music Generation Works

Emotion is detected from face/voice input

Emotion â†’ Prompt mapping (e.g., â€œHappyâ€ â†’ â€œbright upbeat pop melodyâ€¦â€)

Prompt sent to MusicGen running on GPU

Audio is generated â†’ sent back as Base64 â†’ saved as WAV

Track is stored in MongoDB and displayed in the UI

ğŸ›¢ Database Schema (MongoDB)
Generated Tracks
{
  emotion: "Happy",
  variation: 0,
  prompt: "bright upbeat pop melody...",
  audio_url: "/static/generated/track_xyz.wav",
  timestamp: "2025-11-26T12:22:45"
}

Liked Tracks
{
  title: "Happy Track",
  emotion: "Happy",
  audio_url: "...",
  timestamp: "2025-11-26T12:23:10",
  type: "liked"
}

ğŸš€ Future Enhancements

Full voice-based emotion detection

User login system

Playlist creation

Multi-emotion blending

Faster MusicGen inference using ONNX


ğŸ¤ Contributors

C H Prabhu Kishor
Sai Sunil 
Sai Akhil V
